{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!wget \"https://www.dropbox.com/s/4jw31k5mlzcmgis/genres.tar.gz?\"\n",
        "!tar xvf \"/content/genres.tar.gz?\" -C \"/content/\""
      ],
      "metadata": {
        "id": "f6rRE-pKjhZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install shutup"
      ],
      "metadata": {
        "id": "g74zgPkPl4LQ",
        "outputId": "0290a34d-8ad6-4136-c082-1d7c9605493e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting shutup\n",
            "  Downloading shutup-0.2.0-py3-none-any.whl (1.5 kB)\n",
            "Installing collected packages: shutup\n",
            "Successfully installed shutup-0.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "from tf.keras import Sequential\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "from librosa import feature\n",
        "from glob import glob\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import librosa\n",
        "import csv\n",
        "import shutup\n",
        "shutup.please()"
      ],
      "metadata": {
        "id": "r4nvueUlideT",
        "outputId": "038e17fe-18ed-4e52-f9a3-9151306a27f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-0082a15a2635>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# See b/110718070#comment18 for more details about this import.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/models.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmetrics_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptimizer_v1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/metrics.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbase_layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/activations.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0madvanced_activations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeserialize_keras_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mserialize_keras_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInputSpec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_preprocessing_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPreprocessingLayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Image preprocessing layers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_preprocessing_layer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mabc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata_adapter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mversion_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m   \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m  \u001b[0;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m   \u001b[0mpd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tester\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/testing.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m from pandas._testing import (\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0massert_extension_array_equal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0massert_frame_equal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_testing/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m \u001b[0mcython_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cython_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'pandas' has no attribute 'core'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Extraction from Audio data and saving them in their respective .csv üìÅ file üîâ"
      ],
      "metadata": {
        "id": "nOoCZNlWAkgv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "genre = ['blues', 'classical', 'country', 'disco', 'hiphop', 'jazz', 'metal', 'pop', 'reggae', 'rock']\n",
        "\n",
        "header =[\n",
        "  'chroma_stft',\n",
        "  'spectral_centroid',\n",
        "  'spectral_bandwidth',\n",
        "  'spectral_rolloff',\n",
        "  \n",
        "  'chroma_stft_var',\n",
        "  'spectral_centroid_var',\n",
        "  'spectral_bandwidth_var',\n",
        "  'spectral_rolloff_var',\n",
        "  \n",
        "  'rmse',\n",
        "  'zero_crossing_rate',\n",
        "  'librosa.feature.spectral_contrast',\n",
        "  'librosa.feature.spectral_flatness',\n",
        "  'librosa.feature.mfcc',\n",
        "\n",
        "  'rmse_var',\n",
        "  'zero_crossing_rate_var',\n",
        "  'librosa.feature.spectral_contrast_var',\n",
        "  'librosa.feature.spectral_flatness_var',\n",
        "  'librosa.feature.mfcc_var'\n",
        "  ]\n",
        "\n",
        "fn_list_i = [\n",
        "            feature.chroma_stft, feature.spectral_centroid,\n",
        "            feature.spectral_bandwidth, feature.spectral_rolloff\n",
        "            ]\n",
        "\n",
        "fn_list_ii = [librosa.feature.rms,\n",
        "              feature.zero_crossing_rate,\n",
        "              librosa.feature.spectral_contrast,\n",
        "              librosa.feature.spectral_flatness,\n",
        "              librosa.feature.mfcc]\n",
        "  \n",
        "\n",
        "def get_feature_vector(y,sr): \n",
        "    feat_vect_i = [ np.mean(funct(y,sr)) for funct in fn_list_i]\n",
        "    feat_vect_i_var = [ np.var(funct(y,sr)) for funct in fn_list_i]\n",
        "\n",
        "    feat_vect_ii = [np.mean(funct(y)) for funct in fn_list_ii]\n",
        "    feat_vect_ii_var = [np.var(funct(y)) for funct in fn_list_ii]\n",
        "\n",
        "    feature_vector = feat_vect_i + feat_vect_i_var + feat_vect_ii + feat_vect_ii_var \n",
        "    return feature_vector\n",
        "\n",
        "for nowvar in genre:\n",
        "\n",
        "  norm_data_dir = '/content/genres/'+nowvar+'/'\n",
        "  norm_audio_files = glob(norm_data_dir + '*.au')\n",
        "\n",
        "  norm_audios_feat = []\n",
        "  for file in norm_audio_files:\n",
        "    y , sr = librosa.load(file, sr=None)\n",
        "    feature_vector = get_feature_vector(y, sr)\n",
        "    norm_audios_feat.append(feature_vector)\n",
        "\n",
        "  norm_output = nowvar+'.csv'\n",
        "\n",
        "  with open(norm_output,'+w') as f:\n",
        "    csv_writer = csv.writer(f, delimiter = ',')\n",
        "    csv_writer.writerow(header)\n",
        "    csv_writer.writerows(norm_audios_feat)"
      ],
      "metadata": {
        "id": "8JC01selYKcd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reading .csv file and adding a new column type ‚úî"
      ],
      "metadata": {
        "id": "YyJnDYWhUdU9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "blues = pd.read_csv(\"/content/blues.csv\")\n",
        "classical = pd.read_csv(\"/content/classical.csv\")\n",
        "country = pd.read_csv(\"/content/country.csv\")\n",
        "disco = pd.read_csv(\"/content/disco.csv\")\n",
        "hiphop = pd.read_csv(\"/content/hiphop.csv\")\n",
        "jazz = pd.read_csv(\"/content/jazz.csv\")\n",
        "metal = pd.read_csv(\"/content/metal.csv\")\n",
        "pop = pd.read_csv(\"/content/pop.csv\")\n",
        "reggae = pd.read_csv(\"/content/reggae.csv\")\n",
        "rock = pd.read_csv(\"/content/rock.csv\")\n",
        "\n",
        "blues['label'] = 'blues'\n",
        "classical['label'] = 'classical'\n",
        "country['label'] = 'country'\n",
        "disco['label'] = 'disco'\n",
        "hiphop['label'] = 'hiphop'\n",
        "jazz['label'] = 'jazz'\n",
        "metal['label'] = 'metal'\n",
        "pop['label'] = 'pop'\n",
        "reggae['label'] = 'reggae'\n",
        "rock['label'] = 'rock'"
      ],
      "metadata": {
        "id": "uxS2u3A6l361"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating The Main Dataframe for training our Model üö©"
      ],
      "metadata": {
        "id": "1M3nm17t-BMX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_df = pd.DataFrame(columns = rock.columns)"
      ],
      "metadata": {
        "id": "tCnKrertrfBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "genres = [blues, \n",
        "          classical, \n",
        "          country, \n",
        "          disco, \n",
        "          hiphop, \n",
        "          jazz,\n",
        "          metal, \n",
        "          pop,\n",
        "          reggae,\n",
        "          rock]\n",
        "\n",
        "final_df = pd.concat(genres)"
      ],
      "metadata": {
        "id": "PccaQurutNH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df.shape"
      ],
      "metadata": {
        "id": "vr_JSRreCnfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df.sample(20)"
      ],
      "metadata": {
        "id": "RFSsBZYht_0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encoding labels of Target column ‚úà"
      ],
      "metadata": {
        "id": "0ffqCPpM-jJa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "convertor = LabelEncoder()\n",
        "class_list = final_df.iloc[:,-1]\n",
        "y = convertor.fit_transform(class_list)"
      ],
      "metadata": {
        "id": "qsi1Ww0ExiHK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fitting Rest of the columns in StanderdScaler (Using fit_transform for that)"
      ],
      "metadata": {
        "id": "8E1RL8E5-_-n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fit = StandardScaler()\n",
        "X = fit.fit_transform(np.array(final_df.iloc[:,:-1], dtype = float))"
      ],
      "metadata": {
        "id": "zFydlLhfx6cM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting Our Dataset for Training (x_train & y_train) and Testing (y_train & y_test)"
      ],
      "metadata": {
        "id": "Uop8XExG_loN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.33)"
      ],
      "metadata": {
        "id": "2LQbA1CTyGbh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating TrainModel Function for training our RNN model."
      ],
      "metadata": {
        "id": "prVwkKGA_3fC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def trainModel (model, epochs, optimizer, verbose):\n",
        "  batch_size = 128\n",
        "\n",
        "  model.compile(optimizer,\n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics='accuracy')\n",
        "\n",
        "  return model.fit(x_train, y_train,\n",
        "                 validation_data=(x_test, y_test),\n",
        "                 epochs=epochs, batch_size=batch_size, verbose=verbose)"
      ],
      "metadata": {
        "id": "SBMqToRryLgS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our Sequential Model ‚öñ"
      ],
      "metadata": {
        "id": "HYVl2OjiAKP2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential([\n",
        "                             keras.layers.Dense(512, activation='relu', input_shape=(x_train.shape[1],)),\n",
        "                             keras.layers.Dropout(0.2),\n",
        "\n",
        "                             keras.layers.Dense(256, activation='relu'),\n",
        "                             keras.layers.Dropout(0.2),\n",
        "\n",
        "                             keras.layers.Dense(128, activation='relu'),\n",
        "                             keras.layers.Dropout(0.2),\n",
        "\n",
        "                             keras.layers.Dense(64, activation='relu'),\n",
        "                             keras.layers.Dropout(0.2),\n",
        "\n",
        "                             keras.layers.Flatten(),\n",
        "                             keras.layers.Dense(10, activation='softmax')\n",
        "                          ])\n",
        "print(model.summary())\n",
        "model_history = trainModel(model=model, epochs=600, optimizer='adam', verbose=0)"
      ],
      "metadata": {
        "id": "KUPjF4ikzNbT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(x_test, y_test, batch_size=128)\n",
        "print (f\"\\nThe test loss is : {round(test_loss, 2)}\")\n",
        "print(f\"The best test accuracy is : {round(test_acc*100, 2)}%\")"
      ],
      "metadata": {
        "id": "UV7ntOxK6izc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "NpVF7TOCN7c9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def makeAudio_to_Data (path):\n",
        "\n",
        "  norm_audios_feat = []\n",
        "\n",
        "  y , sr = librosa.load(file, sr=None)\n",
        "  feature_vector = get_feature_vector(y, sr)\n",
        "  norm_audios_feat.append(feature_vector)\n",
        "\n",
        "  newDataframe = pd.DataFrame(norm_audios_feat, columns=header)\n",
        "\n",
        "  fit2 = StandardScaler()\n",
        "  numpyArray = fit2.fit_transform(np.array(final_df.iloc[:,:], dtype = float))\n",
        "\n",
        "  return numpyArray, newDataframe\n",
        "\n",
        "data = makeAudio_to_Data ('/content/POP SMOKE - DIOR (OFFICIAL VIDEO).mp3')\n"
      ],
      "metadata": {
        "id": "MLHArnyWQSEK"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "1baa965d5efe3ac65b79dfc60c0d706280b1da80fedb7760faf2759126c4f253"
    },
    "kernelspec": {
      "display_name": "Python 3.8.1 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.1"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "Music_genre_.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}